name: Helm Chart E2E (KinD)

on:
  pull_request:
    paths:
      - 'helm/fume/**'
      - '.github/workflows/helm-e2e.yml'

permissions:
  contents: read

jobs:
  lint:
    name: Lint chart
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Helm
        uses: azure/setup-helm@v4
        with:
          version: v3.14.4

      - name: Helm lint
        run: |
          helm lint ./helm/fume -f ./helm/fume/values-ci.yaml

      - name: Render manifests (sanity)
        run: |
          helm template fume ./helm/fume -f ./helm/fume/values-ci.yaml > /dev/null

  e2e:
    name: Install on KinD and verify rollout
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Create KinD cluster
        uses: helm/kind-action@v1.9.0
        with:
          version: v0.23.0
          node_image: kindest/node:v1.29.4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: v1.29.4

      - name: Detect available storage class for PVC tests
        run: |
          set -euo pipefail
          echo "Listing storage classes:";
          kubectl get storageclass || true
          DEFAULT=$(kubectl get storageclass -o json | jq -r '.items[] | select(.metadata.annotations["storageclass.kubernetes.io/is-default-class"]=="true") | .metadata.name' | head -n1)
          if [ -z "$DEFAULT" ]; then
            for sc in standard local-path; do
              if kubectl get storageclass "$sc" &>/dev/null; then DEFAULT=$sc; break; fi
            done
          fi
          if [ -z "$DEFAULT" ]; then
            echo "::error::No usable storage class found (looked for default, standard, local-path)."
            exit 1
          fi
          echo "Detected storage class: $DEFAULT"
          echo "STORAGE_CLASS=$DEFAULT" >> $GITHUB_ENV

      - name: Setup Helm
        uses: azure/setup-helm@v4
        with:
          version: v3.14.4

      - name: Create namespace
        run: |
          kubectl create namespace fume

      - name: Create required secrets (dummy)
        run: |
          # License secret with a dummy file key
          kubectl -n fume create secret generic fume-license \
            --from-literal=license.key.lic=dummy

          # Application secrets (minimally required keys)
          kubectl -n fume create secret generic fume-secrets \
            --from-literal=FHIR_SERVER_BASE="https://example.com/fhir"

      - name: Install chart with CI overrides
        run: |
          # Install with CI overrides (current test scenario). This uses values-ci.yaml which intentionally keeps fhir cache disabled.
          helm install fume ./helm/fume -n fume -f ./helm/fume/values-ci.yaml

      - name: Wait for backend rollout (initial)
        run: |
          set -euo pipefail
          kubectl -n fume get statefulset fume-backend -o yaml | sed -n '1,120p'
          kubectl -n fume rollout status statefulset/fume-backend --timeout=300s || {
            echo "StatefulSet rollout failed. Gathering diagnostics...";
            kubectl -n fume describe statefulset fume-backend || true;
            kubectl -n fume get pods -l app.kubernetes.io/component=backend -o wide || true;
            kubectl -n fume describe pod fume-backend-0 || true;
            kubectl -n fume get events --sort-by=.metadata.creationTimestamp | tail -n 50 || true;
            exit 1;
          }

      - name: PVC and volume sanity (snapshots/templates disabled scenario)
        run: |
          set -euo pipefail
          echo "List PVCs (expect none since snapshots/templates disabled):"
          kubectl -n fume get pvc || true
          echo "Check that pod mounted expected emptyDir volumes for logs,fhir-cache,index"
          # The previous jq expression tried to serialize the emptyDir object directly, causing a jq CSV/TSV error.
          # Convert volume type to a simple string descriptor instead.
          kubectl -n fume get pod fume-backend-0 -o json | jq -r '.spec.volumes[] | . as $v | [$v.name, (if $v.emptyDir then "emptyDir" elif $v.persistentVolumeClaim then ("pvc:" + $v.persistentVolumeClaim.claimName) elif $v.secret then ("secret:" + $v.secret.secretName) else "other" end)] | @tsv'
          echo "Assert expected emptyDir volumes present and no unexpected PVCs before enabling persistence"
          # Fail if any pvc:* appears (none should before upgrade)
          if kubectl -n fume get pod fume-backend-0 -o json | jq -r '.spec.volumes[] | select(.persistentVolumeClaim) | .name' | grep -q '.'; then
            echo '::error::Found PVC-backed volume before persistence enabled';
            kubectl -n fume get pod fume-backend-0 -o json | jq -r '.spec.volumes[] | select(.persistentVolumeClaim) | .name';
            exit 1;
          fi
          echo "Describe pod (mount errors would appear as Warning events)"
          kubectl -n fume describe pod fume-backend-0 | egrep -i 'Warning|Mount' || true

      - name: Exec volume write test (emptyDir fhir-cache)
        run: |
          set -euo pipefail
          kubectl -n fume exec fume-backend-0 -- sh -c 'echo test > /usr/fume/fhir-packages/ci-write && ls -l /usr/fume/fhir-packages/ci-write'

      - name: Reinstall chart with persistent fhirCache (StatefulSet spec immutability workaround)
        run: |
          set -euo pipefail
          echo "Uninstall initial release (no persistence)"
          helm uninstall fume -n fume
          echo "Install fresh with persistent fhirCache enabled (adds new volumeClaimTemplate)"
          if [ -z "${STORAGE_CLASS:-}" ]; then echo "::error::STORAGE_CLASS not set; previous detection step failed"; exit 1; fi
          echo "Using storage class: $STORAGE_CLASS for fhirCache PVC"
          helm install fume ./helm/fume -n fume -f ./helm/fume/values-ci.yaml \
            --set storage.fhirCache.enabled=true \
            --set storage.fhirCache.size=1Gi \
            --set storage.fhirCache.accessMode=ReadWriteOnce \
            --set storage.fhirCache.storageClass="$STORAGE_CLASS"

      - name: Wait for backend rollout (persistent fhirCache)
        run: |
          set -euo pipefail
          kubectl -n fume rollout status statefulset/fume-backend --timeout=300s || {
            echo "StatefulSet rollout (persistent fhirCache) failed. Diagnostics...";
            kubectl -n fume describe statefulset fume-backend || true;
            kubectl -n fume get pods -l app.kubernetes.io/component=backend -o wide || true;
            kubectl -n fume describe pod fume-backend-0 || true;
            kubectl -n fume get pvc || true;
            kubectl -n fume get events --sort-by=.metadata.creationTimestamp | tail -n 50 || true;
            exit 1;
          }

      - name: Assert fhir-cache PVC present and correctly bound
        run: |
          set -euo pipefail
          echo "List PVCs:"; kubectl -n fume get pvc
          # Expect a PVC whose name includes fhir-cache
          if ! kubectl -n fume get pvc | grep -q 'fhir-cache'; then
            echo "::error::Expected fhir-cache PVC after enabling storage.fhirCache.enabled=true"; exit 1; fi
          # Check access mode and capacity not empty
          kubectl -n fume get pvc -o json | jq -r '.items[] | select(.metadata.name | contains("fhir-cache")) | [.metadata.name, .spec.accessModes[0], .spec.resources.requests.storage] | @tsv'
          # Verify volumeClaimTemplate name matches volumeMount
          kubectl -n fume get statefulset fume-backend -o json | jq -r '.spec.volumeClaimTemplates[] | [.metadata.name] | @tsv'
          if ! kubectl -n fume get statefulset fume-backend -o json | jq -r '.spec.volumeClaimTemplates[].metadata.name' | grep -q '^fhir-cache$'; then
            echo "::error::volumeClaimTemplate name mismatch (expected fhir-cache)"; exit 1; fi

      - name: Validate pod uses PVC (not emptyDir) for fhir-cache
        run: |
          set -euo pipefail
          kubectl -n fume get pod fume-backend-0 -o json | jq -r '.spec.volumes[] | select(.name=="fhir-cache") | .persistentVolumeClaim.claimName' | grep -v '^$'
          if kubectl -n fume get pod fume-backend-0 -o json | jq -e '.spec.volumes[] | select(.name=="fhir-cache" and has("emptyDir"))' >/dev/null; then
            echo "::error::fhir-cache still emptyDir after enabling persistence"; exit 1; fi

      - name: Exec write/read test on persistent fhir-cache
        run: |
          set -euo pipefail
          kubectl -n fume exec fume-backend-0 -- sh -c 'echo persistent > /usr/fume/fhir-packages/ci-persistent && cat /usr/fume/fhir-packages/ci-persistent'

      - name: Server-side dry-run template validation (storage feature)
        run: |
          set -euo pipefail
          # Include CI values so required configMap + secrets keys exist; then override fhirCache toggles.
          helm template fume ./helm/fume -f ./helm/fume/values-ci.yaml \
            --set storage.fhirCache.enabled=true \
            --set storage.fhirCache.size=1Gi > rendered-cache.yaml
          # Fail if legacy misspelled key appears
          if grep -q 'fhircache' rendered-cache.yaml; then echo '::error::Found legacy fhircache token'; exit 1; fi
          # Kubernetes API validation (requires cluster) using dry-run=server
          kubectl apply --dry-run=server -n fume -f rendered-cache.yaml >/dev/null
      - name: Basic smoke listing
        if: always()
        run: |
          kubectl -n fume get all
          #kubectl -n fume describe pod fume-backend-0
          #kubectl -n fume get pvc
          #kubectl -n fume describe pvc snapshots-fume-backend-0
